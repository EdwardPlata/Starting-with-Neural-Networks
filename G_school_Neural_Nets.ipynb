{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1: Solve the MNIST digit problem by building a 1 layer dense neural network using Keras. use 150 neurons and RELU activation function. 10 epochs. no dropout. Use the following as a model (https://github.com/keras-team/keras/blob/master/examples/mnist_mlp.py) (edited) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "num_classes = 10\n",
    "epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train),(x_test,y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(60000,784)\n",
    "x_test= x_test.reshape(10000,784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test=x_test.astype('float32')\n",
    "x_train /=225\n",
    "x_test /=225\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0],'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=keras.utils.to_categorical(y_test,num_classes)\n",
    "y_test=keras.utils.to_categorical(y_test,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(150, activation='relu', input_shape=(784,)))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 150)               117750    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                1510      \n",
      "=================================================================\n",
      "Total params: 119,260\n",
      "Trainable params: 119,260\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer = RMSprop(),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.3212 - acc: 0.9114 - val_loss: 0.1721 - val_acc: 0.9491\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1493 - acc: 0.9569 - val_loss: 0.1237 - val_acc: 0.9626\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1054 - acc: 0.9694 - val_loss: 0.1017 - val_acc: 0.9702\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0819 - acc: 0.9755 - val_loss: 0.0894 - val_acc: 0.9717\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0667 - acc: 0.9805 - val_loss: 0.0819 - val_acc: 0.9740\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0557 - acc: 0.9835 - val_loss: 0.0817 - val_acc: 0.9762\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0465 - acc: 0.9867 - val_loss: 0.0764 - val_acc: 0.9780\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0396 - acc: 0.9882 - val_loss: 0.0727 - val_acc: 0.9791\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0339 - acc: 0.9902 - val_loss: 0.0760 - val_acc: 0.9787\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0294 - acc: 0.9916 - val_loss: 0.0760 - val_acc: 0.9771\n"
     ]
    }
   ],
   "source": [
    "histroy = model.fit(x_train,y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.07600700398278423\n",
      "Test accuracy: 0.9771\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:' ,score[0])\n",
    "print('Test accuracy:',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2: do above again, this time with a deep neural network of three dense layers of 150 neurons each. 10 epochs. how does training time scale? (edited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Dense(150, activation='relu', input_shape=(784,)))\n",
    "model2.add(Dense(150, activation='relu', input_shape=(784,)))\n",
    "model2.add(Dense(150, activation='relu', input_shape=(784,)))\n",
    "\n",
    "model2.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 150)               117750    \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 150)               22650     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 150)               22650     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10)                1510      \n",
      "=================================================================\n",
      "Total params: 164,560\n",
      "Trainable params: 164,560\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy',\n",
    "             optimizer=RMSprop(),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2909 - acc: 0.9123 - val_loss: 0.1277 - val_acc: 0.9609\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1118 - acc: 0.9644 - val_loss: 0.1231 - val_acc: 0.9615\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.0763 - acc: 0.9759 - val_loss: 0.0924 - val_acc: 0.9729\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0578 - acc: 0.9822 - val_loss: 0.0860 - val_acc: 0.9759\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0463 - acc: 0.9850 - val_loss: 0.0911 - val_acc: 0.9743\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0352 - acc: 0.9888 - val_loss: 0.0855 - val_acc: 0.9773\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0293 - acc: 0.9910 - val_loss: 0.0829 - val_acc: 0.9799\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0251 - acc: 0.9920 - val_loss: 0.0999 - val_acc: 0.9772\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.0201 - acc: 0.9936 - val_loss: 0.1032 - val_acc: 0.9781\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0189 - acc: 0.9945 - val_loss: 0.0987 - val_acc: 0.9780\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(x_train,y_train,\n",
    "                     batch_size=128,\n",
    "                     epochs=10,\n",
    "                     verbose=1,\n",
    "                     validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.07600700398278423\n",
      "Test accuracy: 0.9771\n"
     ]
    }
   ],
   "source": [
    "score2 =model2.evaluate(x_test,y_test, verbose=0)\n",
    "print('Test Loss:', score[0])\n",
    "print('Test accuracy:',score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3: Repeat Task #1 using sigmoid activation function. Which works better in terms of test accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3= Sequential()\n",
    "model3.add(Dense(150,activation='sigmoid', input_shape=(784,)))\n",
    "model3.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 150)               117750    \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                1510      \n",
      "=================================================================\n",
      "Total params: 119,260\n",
      "Trainable params: 119,260\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.5028 - acc: 0.8774 - val_loss: 0.2756 - val_acc: 0.9214\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.2468 - acc: 0.9292 - val_loss: 0.2135 - val_acc: 0.9366\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1948 - acc: 0.9436 - val_loss: 0.1753 - val_acc: 0.9489\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1612 - acc: 0.9532 - val_loss: 0.1532 - val_acc: 0.9546\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1377 - acc: 0.9602 - val_loss: 0.1334 - val_acc: 0.9608\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1194 - acc: 0.9657 - val_loss: 0.1215 - val_acc: 0.9642\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1050 - acc: 0.9696 - val_loss: 0.1101 - val_acc: 0.9684\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0930 - acc: 0.9737 - val_loss: 0.1057 - val_acc: 0.9695\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0838 - acc: 0.9759 - val_loss: 0.0967 - val_acc: 0.9711\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0755 - acc: 0.9781 - val_loss: 0.0942 - val_acc: 0.9721\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(x_train,y_train,\n",
    "                     batch_size=batch_size,\n",
    "                     epochs=10,\n",
    "                     verbose=1,\n",
    "                     validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.09415183604508638\n",
      "Test Accuracy: 0.9721\n"
     ]
    }
   ],
   "source": [
    "score=model3.evaluate(x_test,y_test, verbose=0)\n",
    "\n",
    "print('Test loss:',score[0])\n",
    "print('Test Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4: Repeat Task #2 using sigmoid activation function. Which works better in terms of test accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4= Sequential()\n",
    "model4.add(Dense(150, activation='relu', input_shape=(784,)))\n",
    "model4.add(Dense(150, activation='relu', input_shape=(784,)))\n",
    "model4.add(Dense(150, activation='relu', input_shape=(784,)))\n",
    "model4.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_29 (Dense)             (None, 150)               117750    \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 150)               22650     \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 150)               22650     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                1510      \n",
      "=================================================================\n",
      "Total params: 164,560\n",
      "Trainable params: 164,560\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2867 - acc: 0.9136 - val_loss: 0.1330 - val_acc: 0.9584\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.1115 - acc: 0.9663 - val_loss: 0.0928 - val_acc: 0.9701\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0771 - acc: 0.9762 - val_loss: 0.1110 - val_acc: 0.9673\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0577 - acc: 0.9822 - val_loss: 0.0856 - val_acc: 0.9745\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0459 - acc: 0.9858 - val_loss: 0.0807 - val_acc: 0.9782\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.0367 - acc: 0.9884 - val_loss: 0.0758 - val_acc: 0.9804\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.0297 - acc: 0.9908 - val_loss: 0.0851 - val_acc: 0.9780\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0251 - acc: 0.9919 - val_loss: 0.0898 - val_acc: 0.9801\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0198 - acc: 0.9934 - val_loss: 0.1095 - val_acc: 0.9779\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.0183 - acc: 0.9943 - val_loss: 0.0903 - val_acc: 0.9797\n"
     ]
    }
   ],
   "source": [
    "history=model4.fit(x_train, y_train,\n",
    "                 batch_size=128,\n",
    "                 epochs=10,\n",
    "                 verbose=1,\n",
    "                 validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0902665042174137\n",
      "Test Accudacy 0.9797\n"
     ]
    }
   ],
   "source": [
    "score=model4.evaluate(x_test,y_test,verbose=0)\n",
    "print(\"Test Loss:\", score[0])\n",
    "print(\"Test Accudacy\",score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the models above, if any, do you think are “done” training after 10 epochs? Why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model number 4 is the one I'd concider done, cince the accuracy seemed to have platoed at around 0.9943. I believe model 1 and 3 need a few more epochs to be concidered useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
